from langchain.vectorstores import FAISS
from langchain.embeddings import SentenceTransformerEmbeddings

INDEX_DIR = "faiss_index_3"
embedding_model = SentenceTransformerEmbeddings(model_name="jhgan/ko-sbert-sts")
db = FAISS.load_local(INDEX_DIR, embedding_model, allow_dangerous_deserialization=True)

results = db.similarity_search_with_score(
    "2025í•™ë…„ë„ ì„œìš¸ëŒ€ ë²•í•™ì „ë¬¸ëŒ€í•™ì› ëª¨ì§‘ì •ì›ì€?",
    k=5
)

priority_keywords = ["ëª¨ì§‘", "ì •ì›", "ì¸ì›"]

def rerank_with_keywords(results):
    scored = []
    for doc, score in results:
        keyword_score = sum(1 for kw in priority_keywords if kw in doc.page_content)
        # ì ìˆ˜ + í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ë¶€ì—¬
        scored.append((doc, score - keyword_score * 5))  # í‚¤ì›Œë“œ 1ê°œë‹¹ 5ì  ë³´ì •
    return sorted(scored, key=lambda x: x[1])  # ë‚®ì€ ì ìˆ˜ê°€ ë” ìœ ì‚¬

# ì‚¬ìš©
reranked_results = rerank_with_keywords(results)

for i, (doc, score) in enumerate(results, 1):
    print(f"\nğŸ” ê²°ê³¼ {i} (ìœ ì‚¬ë„: {score:.4f}) - {doc.metadata['source']}")
    print(doc.page_content[:500])
